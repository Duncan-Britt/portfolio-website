const portfolioArticles = [{"dateStr":"01/19/2022","html":"<div>\n<a class=\"portfolio_link\" href=\"#splice_writeup\">Splice: A templating language for the front end</a><time datetime=\"2022-01-19\">01/19/2022</time>\n<article id=\"splice_writeup\" loading=\"lazy\">\n<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://duncan-britt.github.io/splice-docs\">Docs</a>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Duncan-Britt/Splice-Lang\">Repo</a>\n<br>\n<br>\n\n<h2 id=\"overview\">Overview</h2>\n<p>Splice supports nesting, partial templates, iterators, conditionals, variable assignment, local scope, comments, escape characters, and escapes HTML by default. In its minified form, it is only _ KB, uncompressed, and has no dependencies.</p>\n<h1 id=\"ive-written-extensively-about-how-to-use-splice-and-that-writing-is-available-on-the-documentation-website-to-avoid-excessive-redundancy-i-would-like-to-use-this-space-to-talk-about-the-implementation-of-the-language-design-processchoices-and-open-issues\">I&#39;ve written extensively about <em>how to use</em> Splice, and that writing is available on the <a href=\"https://duncan-britt.github.io/splice-docs\">documentation website</a>. To avoid excessive redundancy, I would like to use this space to talk about the implementation of the language, design process/choices, and open issues.</h1>\n<br>\n\n<h2 id=\"abstract-syntax-tree-ast\">Abstract Syntax Tree (AST)</h2>\n<p>The AST for Splice begins not with a single root node, but with a collection of its children - the root node is imaginary. There are three types of nodes in the AST:</p>\n<ul>\n<li>text</li>\n<li>binding</li>\n<li>operator</li>\n</ul>\n<p>Text nodes and binding nodes are leaf nodes, whereas operator nodes have a body property which is a subtree. I think of the body as just a special kind of argument that always comes last. For example, the syntax tree for the following splice template:</p>\n<textarea data-lang=\"\">\n<p>Hello, (: username :)! Here are your todos:</p>\n<ul>\n  (:~ each todos as 'todo {\n    <li>\n      <h2>(: todo.name :)</h2>\n      <p>(: todo.description :)</p>\n    </li>\n  }:)\n</ul>\n</textarea>\n<br>\n\n<p>would look something like this:</p>\n<figure>\n\n<p><img src=\"images/ast.svg\" alt=\"diagram\"></p>\n</figure>\n<figcaption>An example Splice AST</figcaption>\n<br>\n\n<h2 id=\"the-front-end-lexer--parser\">The front end: Lexer &amp; Parser</h2>\n<p>The job of the &#39;front end&#39; is to is to take the former and turn it into the latter.</p>\n<br>\n\n<h2 id=\"open-issues\">Open issues</h2>\n<p>It would be good to enable pre-compilation of the templates to enable faster performance. My idea is to have an executable that will parse the template(s) within an html file and compile the syntax tree into javascript code, and then write it to a file. The resulting js file would contain a function which contains the syntax tree written as object/array/string literals. That way there is no parsing client-side, only compilation to html.</p>\n<p>I would also like to work on improving the error messages for the language and writing more extensive tests.</p>\n<br>\n\n</article>\n</div>"},{"dateStr":"11/14/2021","html":"<div>\n<a class=\"portfolio_link\" href=\"#word_ladders_writeup\">AI Generated Word Ladder Puzzles & Web App</a><time datetime=\"2022-01-12\">01/12/2022</time>\n<article id=\"word_ladders_writeup\" loading=\"lazy\">\n<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://word-ladders.herokuapp.com/\">Site</a>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Duncan-Britt/word_ladders#readme\">Repo</a>\n<br>\n<br>\n\n<h2 id=\"overview\">Overview</h2>\n<p>This web app generates word ladders and asks the user to solve them within a maximum number of steps. The puzzles are generated by the server in response to a request and stored in session data. At a high level, the word ladder puzzles are generated by</p>\n<ol>\n<li>making a random word ladder using the <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/filiph/english_words\">5,000 most commonly used English words</a></li>\n<li>finding the shortest path between those first and last words in the ladder using only the 5000 most common English words.</li>\n</ol>\n<p>The length of this shortest path determines the maximum number of steps for the user to solve the puzzle.</p>\n<h4 id=\"additional-features\">Additional Features</h4>\n<ul>\n<li>Signup, Login/Logout, Edit/Delete Account</li>\n<li>History of a user&#39;s previous solutions</li>\n<li>Leaderboard</li>\n</ul>\n<br>\n\n<h2 id=\"technologies-used\">Technologies Used</h2>\n<p>The backend for the Web App is written in Ruby and uses <a href=\"http://sinatrarb.com/intro.html\">Sinatra</a>, <a href=\"https://ruby-doc.org/stdlib-2.7.1/libdoc/erb/rdoc/ERB.html\">ERB</a>, and a PostgreSQL database.</p>\n<br>\n\n<h2 id=\"gameplay\">Gameplay</h2>\n<p>User input steps are considered valid if</p>\n<ol>\n<li>there is one letter of difference between the step and the previous step</li>\n<li>and the word can be found among the <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/cmusphinx/cmudict\">200,000 most commonly used English words</a></li>\n</ol>\n<h4 id=\"examples\">Examples:</h4>\n<ul>\n<li>buy =&gt; buys: valid</li>\n<li>buy =&gt; bus: valid</li>\n<li>buy =&gt; busy: valid</li>\n<li>busy =&gt; buoy: valid</li>\n<li>has =&gt; as: valid</li>\n<li>use =&gt; bus: invalid</li>\n<li>abuse =&gt; bus: invalid</li>\n</ul>\n<br>\n\n<h2 id=\"generating-puzzles\">Generating Puzzles</h2>\n<p>I parsed the data from a csv file of 5,000 most commonly used English words and created a graphical representation of the data, which I then serialized to a YAML file so that my ruby code can more efficiently recreate it. Each vertex in the graph represents a word. The neighbors of every vertex in the graph are the vertices whose word is &quot;adjacent&quot; to the word stored by the vertex.</p>\n<figure>\n\n<p><img src=\"images/graph.svg\" alt=\"diagram\"></p>\n</figure>\n<figcaption>\"The\" and its neighbors.</figcaption>\n\n<p>Among my 5k words, it is possible find two words between which there simply is no path. So inorder to not waste time solving for the shortest path between two words for whom no path exists, my program first creates a ladder randomly.</p>\n<textarea data-lang=\"ruby\">\nclass WordGraph\n  #...\n  def make_ladder(length)\n    ladder = nil\n    loop do\n      v = random_vertex\n      ladder = make_sub_ladder(v: v, length: length, prev: [])\n      break if ladder\n    end\n    ladder.map { |v| v.data }\n  end\n\n  def make_sub_ladder(v: random_vertex, length: 3, prev: [])\n    ladder = [v]\n    return ladder if ladder.length == length\n\n    neighbors = v.neighbors - prev\n    neighbors.select! do |neighbor|\n      prev.none? { |v| WordGraph.adjacent?(v.data, neighbor.data) }\n    end\n\n    return nil if neighbors.empty?\n    neighbors.shuffle!\n    sub_ladder = nil\n    neighbors.each do |n|\n      sub_ladder = make_sub_ladder(v: n, length: length - 1, prev: ladder + prev)\n      break if sub_ladder\n    end\n\n    sub_ladder && ladder + sub_ladder\n  end\n  #...\nend\n</textarea>\n<br>\n\n<p>Then, my program takes the first and last words from the random ladder, ignores the rest, and attempts to find the shortest path between them using a breadth first search of the graph. If it takes too long, (if the queue is getting too long) it will inform the calling method which will try again with an entirely new random word ladder.</p>\n<textarea data-lang=\"ruby\">\nclass Vertex\n  #...\n  def traverse(end_point)\n    return [self.data, end_point.data] if self.neighbors.include? end_point\n\n    queue = [[self]]\n    while (queue.length != 0)\n      if queue.length > 1_000_000\n        return :timeout\n      end\n      path = queue.shift\n      node = path[-1]\n      return path.map { |n| n.data } if node == end_point\n\n      node.neighbors.each do |neighbor|\n        next if path.include?(neighbor)\n        new_path = path.dup\n        new_path << neighbor\n        queue.push(new_path)\n      end\n    end\n  end\n  #...\nend\n</textarea>\n<br>\n<br>\n\n<h2 id=\"open-issues\">Open Issues</h2>\n<p>I decided to use 5,000 words after some amount of trial and error. With larger word sets, it takes longer and longer to deserialize the graph. I would like it be able to make use of a broader vocabulary, and I have some ideas for how to make that happen. Although there are probably a variety of ways I could improve the speed of generation of puzzles (multithreading, for instance), I think the best solution is to make it a non-issue by caching previously generated word ladders and reusing them. The reason I haven&#39;t done that already basically comes down to the fact that I wanted to get the app up and running, and caching previously generated word ladders introduces some complexity I didn&#39;t want to deal with just yet. But that would be the next step.</p>\n<p>Caching previously generated puzzles opens up a number of possibilities such as:</p>\n<ul>\n<li>displaying other user&#39;s solutions for the same puzzle</li>\n<li>ranking puzzles based on quality/difficulty</li>\n<li>Algorithmically determining which puzzle to show the user</li>\n<li>Massively broadening the vocabulary of the word set</li>\n</ul>\n<p>I have some plans to make the puzzles more conceptually interesting by making them out of conceptually related words rather than just random, but that requires a greater vocabulary first.</p>\n<p>Another issue is that the leaderboard is too simplistic. It only measures the number of puzzles a user has solved. There&#39;s no extra credit for getting a puzzle in fewer steps, solving a puzzler faster, solving a harder puzzle, etc....</p>\n<br>\n\n</article>\n</div>"}]